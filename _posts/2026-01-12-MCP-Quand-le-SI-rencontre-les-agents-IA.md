---
layout: post
title: "MCP - Quand le SI rencontre les agents IA"
date: 2026-01-12 10:00:00 +0100
categories: IA
author: Baptiste Mac√©
---

## **Du syst√®me d'information classique √† l'architecture agentique gouvern√©e**

### **Introduction : Comprendre l'Agent et son √âcosyst√®me**

L'int√©gration de l'intelligence artificielle dans les syst√®mes d'information traditionnels repr√©sente un d√©fi majeur, principalement en raison de la nature fondamentalement diff√©rente de ces deux mondes. Pour appr√©hender cette complexit√©, il est essentiel de commencer par d√©finir les acteurs cl√©s et les concepts qui les entourent.

Un **agent IA** est un programme logiciel con√ßu pour interagir avec son environnement. Sa capacit√© √† "percevoir" signifie qu'il est configur√© pour **recevoir des entr√©es de donn√©es structur√©es ou non structur√©es** (par exemple, du texte, des signaux num√©riques, des donn√©es de capteurs, des retours d'API) et √† les traiter. Son fonctionnement repose sur des **algorithmes et des mod√®les computationnels** qui lui permettent de traiter ces entr√©es, de simuler des processus d√©cisionnels et d'ex√©cuter des actions. Il est programm√© pour atteindre des objectifs sp√©cifiques.

Contrairement aux applications logicielles purement d√©terministes qui suivent un ensemble fixe d'instructions, un agent IA peut pr√©senter un comportement non-d√©terministe. Cela signifie que, face √† des entr√©es ou des contextes similaires, il peut g√©n√©rer des r√©ponses ou suivre des chemins d'ex√©cution diff√©rents. Cette variabilit√© est inh√©rente √† la complexit√© de ses mod√®les internes et de son environnement d'interaction, et n'implique pas une conscience ou une intention humaine.

Pour fonctionner, un agent IA dispose de plusieurs **outils** ou capacit√©s :

*  **LLM (Large Language Model) embarqu√©** :  
Au c≈ìur de nombreux agents IA modernes se trouve un mod√®le de langage √©tendu, entra√Æn√© sur de vastes ensembles de donn√©es textuelles pour pr√©dire la suite la plus probable d‚Äôune s√©quence de mots. Le langage y est repr√©sent√© sous forme de **vecteurs num√©riques (embeddings)** projet√©s dans un espace de grande dimension. La **distance entre ces vecteurs** permet de mesurer la proximit√© s√©mantique entre mots, phrases ou documents, m√™me lorsqu‚Äôils n‚Äôemploient pas les m√™mes termes. Le LLM exploite ces relations de distance pour identifier des patterns, r√©aliser des inf√©rences statistiques et g√©n√©rer des r√©ponses coh√©rentes. Il ne comprend pas le sens au sens humain, mais manipule des similarit√©s vectorielles apprises lors de l‚Äôentra√Ænement. L‚Äôagent interagit avec ce LLM via des appels programmatiques afin d‚Äôinterpr√©ter les requ√™tes, d√©tecter des intentions et formuler des r√©ponses adapt√©es.

* **MCP (Model Context Protocol)** : Ce protocole est un m√©canisme de communication essentiel pour qu'un agent puisse interagir de mani√®re structur√©e et gouvern√©e avec un syst√®me d'information. Le MCP permet √† l'agent d'ex√©cuter des fonctions sp√©cifiques (appel√©es "tools") ou de lire des ressources (donn√©es) du SI. Il agit comme une interface standardis√©e, traduisant les requ√™tes de l'agent en appels d√©terministes pour le syst√®me sous-jacent.  

* **A2A (Agent-to-Agent)** : Ce terme d√©crit la capacit√© d'un agent √† communiquer et √† √©changer des informations ou des requ√™tes avec d'autres programmes agents IA. Il s'agit d'une interaction entre entit√©s logicielles autonomes, souvent pour la d√©l√©gation de t√¢ches ou la combinaison d'expertises. Il est crucial de noter que les outils MCP sont con√ßus pour interagir avec des syst√®mes d'information d√©terministes et non pas pour orchestrer une cascade d'agents A2A, afin d'√©viter une complexit√© et une impr√©visibilit√© op√©rationnelles.

* **RAG (Retrieval-Augmented Generation)** :Ce terme d√©crit une architecture dans laquelle un agent IA **interagit avec une base de connaissances externe** afin d‚Äôenrichir son raisonnement avant g√©n√©ration. Il s‚Äôagit d‚Äôune **interaction contr√¥l√©e entre un agent g√©n√©ratif et un syst√®me de r√©cup√©ration d‚Äôinformation**, g√©n√©ralement bas√© sur des embeddings et une recherche vectorielle.

* **multi-turn (ou conversationnel √† plusieurs tours)** : C‚Äôest un mode d‚Äôinteraction o√π l‚Äôagent maintient un √©tat conversationnel et une m√©moire des √©changes pr√©c√©dents. Cela lui permet d‚Äôint√©grer le contexte historique dans ses d√©cisions et ses r√©ponses, de poser des questions de clarification et d‚Äôadapter son comportement au fil d‚Äôune s√©quence d‚Äôinteractions prolong√©e. Cette capacit√© est toutefois **contrainte par la taille du contexte d‚Äôentr√©e (nombre de tokens)** : plus la fen√™tre de contexte est large, plus l‚Äôagent peut conserver finement l‚Äôhistorique de la conversation. √Ä l‚Äôinverse, lorsque cette limite est atteinte, l‚Äôagent doit **rationnaliser le contexte** (r√©sum√©s, oubli de d√©tails, s√©lection d‚Äô√©l√©ments jug√©s pertinents) pour poursuivre l‚Äô√©change.


### **1\. Avant MCP : un SI pr√©visible et rigide**

Dans un syst√®me d'information (SI) classique, le fonctionnement est intrins√®quement d√©terministe. Chaque composant, de l'application √† l'API et √† la base de donn√©es, ex√©cute des op√©rations et des flux de donn√©es pr√©d√©finis et reproductibles. Les r√®gles m√©tier sont impl√©ment√©es de mani√®re statique dans le code, et les sc√©narios d'erreur sont g√©n√©ralement anticip√©s et g√©r√©s de mani√®re explicite. Ce mod√®le d√©terministe est efficace et fiable jusqu'√† l'int√©gration d'un agent IA.

### **2\. Le choc : connecter un agent √† un SI**

La tentative initiale d'int√©grer un agent IA dans un SI classique se heurte souvent √† des difficult√©s inattendues. Un agent, par sa nature non-d√©terministe et son fonctionnement bas√© sur l'inf√©rence plut√¥t que sur des instructions s√©quentielles strictes, introduit une variabilit√© que les syst√®mes traditionnels ne sont pas con√ßus pour g√©rer. L'agent peut initier des s√©quences d'appels impr√©vues, rendre la tra√ßabilit√© des erreurs complexe (il est difficile de d√©terminer l'origine d'un dysfonctionnement entre le prompt, le mod√®le de l'agent et l'API du SI), et g√©n√©rer des co√ªts op√©rationnels non ma√Ætris√©s. Le probl√®me fondamental r√©side dans l'absence d'un protocole standardis√© pour √©tablir un contrat d'interface clair entre le comportement exploratoire et probabiliste d'un LLM au sein d'un agent IA et la logique rigide et pr√©visible d'un SI. Les deux entit√©s op√®rent selon des paradigmes incompatibles sans un m√©canisme d'interm√©diation.

### **3\. MCP : une fa√ßade contractuelle entre l'IA et le SI**

C'est ici que le Model Context Protocol (MCP) intervient, en proposant une solution. Plut√¥t que de permettre aux agents IA d'interagir directement avec les composants d'un SI, le MCP instaure un serveur interm√©diaire. Ce serveur expose un ensemble contr√¥l√© et standardis√© de capacit√©s du SI sous forme de "tools" et de "ressources". Concr√®tement, l'interaction se structure ainsi : 

Agent IA ‚Üí Serveur MCP ‚Üí SI existant (ERP, CRM, bases de donn√©es, APIs) 

Le MCP remplit une triple fonction : il agit comme une fa√ßade technique, une couche de gouvernance pour contr√¥ler l'acc√®s et l'utilisation des fonctionnalit√©s du SI, et un langage commun permettant aux mod√®les d'IA et aux syst√®mes existants de dialoguer de mani√®re intelligible et contr√¥l√©e.

**Il est crucial de comprendre que MCP ne formalise pas un "contrat" directement avec le LLM de l'agent.** Le LLM, en tant qu'interpr√®te statistique, n'est pas une entit√© contractante ; il agit selon les sch√©mas appris lors de son entra√Ænement. **Le contrat est √©tabli entre le d√©veloppeur qui configure l'agent (et donc son usage du MCP) et le SI.** MCP fournit une **couche de transport et de gouvernance standardis√©e** qui permet de canaliser les requ√™tes potentielles de l'agent vers des points d'acc√®s d√©finis et contr√¥l√©s du SI. La nature intrins√®quement "floue" ou impr√©visible du LLM subsiste, mais MCP permet d'encadrer et de s√©curiser la mani√®re dont ses requ√™tes se traduisent en actions sur le SI. M√™me avec MCP, le LLM peut toujours g√©n√©rer des tentatives d'appels de tools avec des arguments non valides ou "halluciner" des ressources inexistantes ; c'est au MCP (et √† la configuration des tools) de g√©rer ces sc√©narios de mani√®re robuste.

### **4\. Ce que MCP expose r√©ellement**

MCP structure les interactions autour de trois types d'√©l√©ments :

**Les ressources** (en lecture) : ce sont les donn√©es consultables comme des documents, des objets m√©tier ou des √©tats syst√®me.

**Les tools** (pour agir) : ce sont des fonctions ex√©cutables. Par exemple, cr√©er une facture, d√©clencher un workflow ou effectuer un calcul complexe.

**Le contexte** : √ßa inclut les r√®gles m√©tier, les prompts syst√®me et les contraintes d'usage.

  #### **4.1 Concr√®tement, comment √ßa marche ?**

MCP, c'est avant tout **un protocole de communication standardis√©**. Il repose sur **JSON-RPC 2.0**, un format d'appel de proc√©dure √† distance simple et l√©ger.

Contrairement √† REST qui est orient√© ressources (GET /users/123, POST /orders), JSON-RPC se concentre sur l'appel de m√©thodes : vous envoyez une requ√™te JSON avec le nom de la m√©thode et ses param√®tres, vous recevez une r√©ponse JSON avec le r√©sultat ou une erreur. C'est tout. Pas de verbes HTTP √† g√©rer, pas de conventions d'URL ‚Äî juste des appels de fonctions structur√©s.

Exemple d'appel JSON-RPC :

```json

{
  "jsonrpc": "2.0",
  "method": "tools/call",
  "params": {
    "name": "create_invoice",
    "arguments": {"client_id": "12345"}
  },
  "id": 1
}

```

Simple, direct, pr√©visible.

Le serveur MCP expose plusieurs **routes standardis√©es** :

* tools/list : pour d√©couvrir les outils disponibles  
* tools/call : pour ex√©cuter un outil sp√©cifique  
* resources/list : pour lister les ressources accessibles  
* resources/read : pour lire le contenu d'une ressource  
* prompts/list et prompts/get : pour r√©cup√©rer des contextes pr√©d√©finis

  #### **4.2 Les modes de communication**

Les √©changes peuvent se faire de deux mani√®res principales :

**Via stdio** (entr√©e/sortie standard) : le serveur MCP tourne **en local, embarqu√© avec l'agent**. C'est comme un processus qui communique directement via son stdin/stdout. Pas de r√©seau, pas de latence r√©seau, tout se passe dans la m√™me machine. C'est rapide, simple, mais √ßa limite √† des sc√©narios locaux ou monolithiques.

**Via SSE** (Server-Sent Events) : l√†, le serveur MCP est **distant**. Il peut √™tre h√©berg√© ailleurs, mutualis√© entre plusieurs agents, et il communique via HTTP avec du streaming unidirectionnel (le serveur peut envoyer des √©v√©nements au client en continu). C'est plus flexible pour des architectures distribu√©es, mais √ßa introduit de la latence r√©seau et des questions de s√©curit√©.

Le choix d√©pend de votre architecture :

* **stdio** pour un assistant local desktop  
* **SSE** pour un chatbot distribu√© en production

Ce qui est malin, c'est que MCP ne r√©invente pas la roue. Il s'appuie sur des standards existants (JSON-RPC, HTTP, WebSocket) et d√©finit juste une **convention** sur ce qu'on expose et comment on le structure.

Un point important √† comprendre : **MCP ne fait rien d'intelligent en soi**. Il ne raisonne pas, il n'optimise rien. Il fournit juste un cadre standardis√© qui rend l'intelligence du mod√®le possible et contr√¥lable. C'est une couche de contrat, pas une couche de magie.

### **5\. Mais pourquoi un agent "cherche" des tools ?**

C'est une question que beaucoup de gens se posent, et c'est normal.

  **Les agents ont simplement √©t√© entra√Æn√©s √† le faire**

Les grands mod√®les de langage modernes ne font pas que g√©n√©rer du texte. Ils ont aussi appris √† agir. Pendant leur entra√Ænement, ils ont vu des milliers d'exemples o√π il fallait r√©fl√©chir √† un objectif, appeler une fonction, observer le r√©sultat, puis d√©cider de la suite.

Ils ont int√©gr√© le fait que certaines informations ne sont pas disponibles dans leur contexte imm√©diat, et que certaines actions n√©cessitent un appel externe. Du coup, MCP s'int√®gre naturellement dans leur fa√ßon de fonctionner.

### **6\. Fine-tuning, RLHF et usage des tools (en profondeur)**

  #### **6.1 Fine-tuning supervis√©**

Pendant cette phase d'entra√Ænement, le mod√®le est expos√© √† des exemples annot√©s montrant les bonnes et les mauvaises d√©cisions, ainsi que des appels de fonctions bien form√©s. Il apprend progressivement quand appeler un tool, lequel choisir, et avec quels param√®tres.

  #### **6.2 RLHF (Reinforcement Learning from Human Feedback)**

Ensuite vient le RLHF, o√π les comportements efficaces sont r√©compens√©s et les mauvais sont p√©nalis√©s. Par exemple, si l'agent appelle trois tools alors qu'un seul suffit, ou s'il ignore une capacit√© pourtant disponible, il est sanctionn√©.

R√©sultat : l'agent d√©veloppe une sorte d'intuition sur le rapport co√ªt/b√©n√©fice de ses actions.

  #### **6.3 Pourquoi il explore quand m√™me ?**

Parce que le contexte change constamment, les tools sont d√©couverts de mani√®re dynamique, et MCP ne garantit pas qu'il n'y ait qu'une seule fa√ßon s√©mantique de faire quelque chose.

Donc l'agent fait exactement ce qu'on lui a appris : il explore pour r√©duire l'incertitude.

### **7\. Le r√¥le fondamental des embeddings**

  #### **7.1 Ce que font les embeddings**

Les descriptions des tools, ressources et contextes sont transform√©es en vecteurs puis compar√©es √† l'objectif actuel de l'agent. Il choisit le tool qui est s√©mantiquement le plus proche, pas forc√©ment celui qui a le bon nom.

  #### **7.2 Exemple critique**

Imaginons deux tools : get\_client\_from\_crm et get\_client\_from\_erp.

**Description minimaliste (probl√©matique) :**

```json

{
  "name": "get_client_from_crm",
  "description": "R√©cup√®re les informations d'un client"
}
{
  "name": "get_client_from_erp",
  "description": "R√©cup√®re les informations d'un client"
}

```

Si l'objectif de l'utilisateur est "cr√©er une facture", les embeddings de ces deux descriptions sont quasi identiques. L'agent ne sait pas lequel choisir. R√©sultat : il appelle les deux pour √™tre s√ªr, ou pire, il choisit au hasard.

**Description enrichie (bonne pratique) :**

```json
{
  "name": "get_client_from_crm",
  "description": "R√©cup√®re les donn√©es commerciales d'un client : historique des interactions, contacts, opportunit√©s, cycle de vente. Utilis√© pour les actions marketing et le suivi commercial."
}
{
  "name": "get_client_from_erp",
  "description": "R√©cup√®re les donn√©es financi√®res et comptables d'un client : adresse de facturation, conditions de paiement, historique des factures, solde comptable. Utilis√© pour la facturation et la gestion financi√®re."
}
```

Maintenant, si l'objectif est "cr√©er une facture", les embeddings vont naturellement rapprocher les concepts de "facture", "paiement", "comptable" et "ERP". L'agent choisira directement get\_client\_from\_erp, sans h√©sitation.

#### **Autre exemple : ambigu√Øt√© sur les produits**

**Descriptions floues :**

```json
{
  "name": "search_products",
  "description": "Cherche des produits"
}
{
  "name": "get_product_catalog",
  "description": "R√©cup√®re le catalogue produits"
}

```

Objectif utilisateur : "Montre-moi les nouveaux smartphones"

Que fait l'agent ? Il ne sait pas. Les deux semblent pertinents. Il va probablement appeler les deux.

**Descriptions enrichies :**

```json

{
  "name": "search_products",
  "description": "Recherche des produits disponibles en stock avec filtres (prix, cat√©gorie, disponibilit√©). Retourne les produits vendables imm√©diatement avec leur prix actuel et stock temps r√©el."
}
{
  "name": "get_product_catalog",
  "description": "R√©cup√®re l'ensemble du catalogue produit avec descriptions d√©taill√©es, fiches techniques et sp√©cifications. Utilis√© pour consulter les caract√©ristiques compl√®tes, pas pour v√©rifier la disponibilit√©."
}

```

Maintenant, pour "Montre-moi les nouveaux smartphones", l'agent comprend que search\_products est le bon choix car l'utilisateur veut probablement voir ce qui est disponible √† la vente.

#### **Exemple suppl√©mentaire : actions vs consultation**

**Sans contexte :**

```json

{
  "name": "update_order",
  "description": "Met √† jour une commande"
}
{
  "name": "get_order",
  "description": "R√©cup√®re une commande"
}

```

Demande utilisateur : "Quelle est le statut de ma commande \#12345 ?"

Risque : l'agent pourrait confondre "statut" avec "mise √† jour" si les embeddings sont mal align√©s.

**Avec contexte :**

```json

{
  "name": "update_order",
  "description": "Modifie les informations d'une commande existante : adresse de livraison, articles, quantit√©s. Action qui impacte les donn√©es. N√©cessite une confirmation."
}
{
  "name": "get_order",
  "description": "Consulte les informations d'une commande : statut, articles command√©s, adresse de livraison, date de livraison pr√©vue. Lecture seule, aucune modification."
}

```

Ici, "statut" et "consulte" sont s√©mantiquement proches. L'agent choisit get\_order sans ambigu√Øt√©.

#### **La r√®gle d'or**

**Plus vous donnez de contexte m√©tier dans la description, plus vous guidez les embeddings vers le bon outil.**

Ne d√©crivez pas juste ce que fait le tool. D√©crivez :

* **Quand** l'utiliser  
* **Quel type de donn√©es** il manipule  
* **Dans quel contexte m√©tier** il s'inscrit  
* **Lecture ou √©criture ?**  
* **Action r√©versible ou non ?**

Les embeddings ne lisent pas votre code. Ils lisent vos descriptions. Et c'est l√† que tout se joue.

  #### **7.3 Danger r√©el**

Si les descriptions des tools sont vagues ou se chevauchent, les embeddings vont se ressembler. L'agent va h√©siter et finir par appeler plusieurs tools pour √™tre s√ªr.

### **8\. MCP face √† un SI classique**

**MCP ne remplace pas le SI. Il ajoute une couche d'abstraction par-dessus.**

Votre SI existe toujours avec ses APIs, ses bases de donn√©es, son ERP, son CRM. MCP vient se poser au-dessus pour exposer ces capacit√©s d'une mani√®re que l'agent peut comprendre et manipuler.

#### **Ce que √ßa change concr√®tement**

**Avant MCP :**

* L'agent appelle directement vos APIs REST/GraphQL  
* Il doit conna√Ætre la structure exacte de vos endpoints  
* Chaque modification d'API casse potentiellement l'agent  
* Pas de couche de contr√¥le entre l'agent et vos syst√®mes critiques

**Avec MCP :**

* L'agent appelle des tools standardis√©s (create\_invoice, get\_client)  
* Le serveur MCP traduit ces intentions en appels API concrets  
* Vous pouvez changer votre API interne sans toucher √† l'agent  
* Vous contr√¥lez ce qui est expos√©, comment et √† qui

#### **Ce que MCP apporte vraiment**

**Abstraction** : l'agent ne sait pas (et n'a pas besoin de savoir) si get\_client interroge un CRM, un ERP ou une base PostgreSQL.

**Gouvernance** : vous d√©cidez quels outils exposer, avec quelles limites (quotas, permissions, validation).

**D√©couvrabilit√©** : l'agent peut demander "qu'est-ce que je peux faire ?" via tools/list au lieu de parcourir une documentation OpenAPI.

**Intention m√©tier vs API technique** : au lieu d'exposer POST /api/v2/invoices avec 15 champs obligatoires, vous exposez create\_invoice\_from\_quote qui encapsule la logique m√©tier.

#### **Le co√ªt de cette abstraction**

MCP ajoute :

* Une couche suppl√©mentaire (latence)  
* De la s√©rialisation JSON-RPC  
* Du raisonnement LLM pour choisir le bon tool  
* De la complexit√© op√©rationnelle

**MCP n'optimise pas le SI en tant que tel.** Il l'ouvre √† une nouvelle cat√©gorie d'interactions, impr√©visibles, exploratoires, conversationnelles, qui n'√©taient tout simplement pas possibles avant.

C'est un peu comme ajouter une API GraphQL par-dessus votre REST : √ßa ne rend pas votre base de donn√©es plus rapide, mais √ßa change radicalement la fa√ßon dont on peut l'interroger.

### **9\. Limites de MCP ‚Äì Performance et latence**

  #### **9.1 Chaque appel a un co√ªt**

Il y a le raisonnement du mod√®le, la s√©rialisation des donn√©es, le r√©seau, l'orchestration... Un agent qui fait 10 appels MCP va m√©caniquement avoir 10 fois plus de latence qu'un appel API direct.

  #### **9.2 MCP n'est pas temps r√©el**

Ce n'est clairement pas adapt√© aux chemins critiques ni aux syst√®mes qui n√©cessitent une tr√®s haute fr√©quence de traitement. MCP, c'est fait pour la d√©cision, pas pour la micro-optimisation.

### **10\. Redondance : le pi√®ge architectural**

  #### **10.1 Redondance des tools**

Quand on a plusieurs tools qui font essentiellement la m√™me chose avec des descriptions proches, on se retrouve avec des appels multiples, des co√ªts inutiles et des d√©cisions parfois incoh√©rentes.

**Mais il y a un pi√®ge encore plus grave :** MCP est con√ßu pour qu'un serveur MCP appelle **votre SI classique** ‚Äî vos APIs, vos bases de donn√©es, votre ERP. Ce n'est **pas** fait pour qu'un serveur MCP appelle un autre agent IA ou d√©clenche une nouvelle boucle de raisonnement.

Si vous commencez √† avoir des tools MCP qui eux-m√™mes d√©clenchent des agents, vous cr√©ez une cascade de raisonnements non-d√©terministes, avec :

* Des co√ªts qui explosent exponentiellement  
* Une latence impr√©visible (agent qui appelle un agent qui appelle un agent...)  
* Une impossibilit√© totale de tracer ce qui s'est r√©ellement pass√©  
* Des boucles infinies potentielles

**MCP doit √™tre la couche de terminaison** : l'agent appelle MCP, MCP appelle du d√©terministe (API, base de donn√©es, fonction), et retourne un r√©sultat. C'est tout.

  #### **10.2 R√®gle d'or MCP**

**Un tool \= une intention m√©tier claire.**

Et cette intention doit se traduire par un appel d√©terministe √† votre SI. Pas par un autre agent. Pas par un autre LLM. Pas par une nouvelle phase de raisonnement.

MCP, c'est la fronti√®re entre l'intelligence (l'agent) et l'ex√©cution (le SI). Ne brouillez pas cette ligne.

### **11\. Co√ªt environnemental üå±**

Chaque boucle de raisonnement consomme des tokens, du calcul GPU et de l'√©nergie. Un agent qui explore beaucoup peut facilement consommer 10 √† 100 fois plus qu'un flux API classique.

**MCP a un co√ªt. Point.**

Et ce co√ªt ‚Äî qu'il soit financier, environnemental ou en latence ‚Äî doit avoir un **ROI clair**. Si vous ne pouvez pas justifier en quoi l'usage de MCP apporte une valeur m√©tier sup√©rieure au co√ªt engendr√©, alors la r√©ponse est simple : **n'utilisez pas MCP**.

#### **Quand le co√ªt est justifi√©**

* Vous orchestrez plusieurs syst√®mes complexes  
* La d√©cision n√©cessite du contexte m√©tier dynamique  
* L'interaction conversationnelle a une vraie valeur (support client, conseil)  
* Vous automatisez des t√¢ches cognitives √† forte valeur ajout√©e

#### **Quand le co√ªt n'est pas justifi√©**

* Vous faites du CRUD simple d√©guis√©  
* Une requ√™te SQL ou une API REST suffit  
* Le parcours utilisateur est d√©terministe  
* Vous ajoutez de l'IA "parce que c'est tendance"

**La question √† se poser syst√©matiquement :** est-ce que le b√©n√©fice de cette interaction agentique vaut 10 √† 100 fois le co√ªt d'un appel API classique ?

Si la r√©ponse n'est pas un "oui" franc, vous √™tes probablement en train de sur-architecturer.

MCP peut amplifier consid√©rablement l'impact environnemental et financier si l'architecture n'est pas bien pens√©e. Ne l'utilisez pas par d√©faut. Utilisez-le **quand √ßa a du sens**.

### **12\. Anti-patterns MCP**

#### **Quand MCP est une mauvaise r√©ponse (ou une r√©ponse surdimensionn√©e)**

MCP est puissant, mais ce n'est vraiment pas un outil universel. L'une des erreurs les plus fr√©quentes concerne les chatbots de recherche produit bas√©s sur du RAG.

  #### **12.1 Anti-pattern n¬∞1 : MCP pour une simple recherche produit**

Prenons un chatbot e-commerce qui doit chercher des produits, filtrer par prix, cat√©gorie et stock, puis afficher les r√©sultats.

L'architecture na√Øve consisterait √† faire passer tout √ßa par MCP avec un tool `search_products` qui interroge la base produits.

Le probl√®me ? La recherche produit est d√©terministe, tr√®s structur√©e, tr√®s fr√©quente et sensible √† la latence. Or MCP introduit du raisonnement inutile, des appels r√©p√©t√©s, une latence variable et un co√ªt par requ√™te.

On utilise un agent l√† o√π un simple moteur de recherche suffirait largement.

  #### **12.2 Anti-pattern n¬∞2 : RAG \+ MCP en cascade**

C'est une architecture qu'on voit tr√®s souvent : l'utilisateur envoie une question, le mod√®le utilise le RAG pour comprendre, puis appelle MCP pour confirmer, compare les r√©sultats et reformule.

R√©sultat : on r√©cup√®re deux fois la m√™me information, on a de la redondance s√©mantique, les co√ªts sont multipli√©s, et au final le b√©n√©fice est quasi nul.

Sympt√¥me typique qu'on entend : "Notre chatbot fonctionne bien, mais il co√ªte tr√®s cher."

  #### **12.3 Pourquoi le RAG suffit dans ce cas**

Le RAG est con√ßu exactement pour √ßa : recherche s√©mantique, filtrage rapide, haute fr√©quence et faible latence. Le moteur vectoriel est optimis√©, d√©terministe, et ne raisonne pas inutilement.

MCP n'apporte strictement aucune valeur ajout√©e dans ce contexte.

  #### **12.4 Anti-pattern n¬∞3 : un tool MCP "search\_products" trop g√©n√©rique**

Si vous avez juste un tool avec une description floue comme "Recherche des produits", vous allez cr√©er des embeddings flous, des appels multiples et de l'exploration inutile.

Mieux vaut d√©couper par intention claire : `search_products_by_category`, `search_products_in_stock`, `get_product_details`, `create_quote`.

  #### **12.5 R√®gle de d√©cision simple**

**Si la r√©ponse peut √™tre obtenue sans raisonnement, sans orchestration et sans d√©cision, MCP est probablement un anti-pattern.**

  #### **12.6 R√©sum√© des anti-patterns MCP courants**

* MCP pour du CRUD simple  
* MCP pour de la recherche full-text ou vectorielle  
* MCP pour des parcours ultra fr√©quents  
* MCP sans gouvernance des tools  
* MCP \+ RAG redondant

#### 

## **Conclusion ‚Äì MCP n'est pas une baguette magique**

MCP ne rend pas l'IA :

* plus rapide  
* moins ch√®re  
* plus intelligente par d√©faut

Il la rend :

* **int√©grable** (via un protocole standardis√©)  
* **gouvernable** (avec des tools ma√Ætris√©s)  
* **industrialisable** (dans un SI existant)

#### **MCP est une brique d'architecture**

Comme toute brique, mal pos√©e, elle fragilise l'ensemble. Bien pos√©e, elle ouvre des possibilit√©s qui n'existaient pas.

#### **Les questions √† se poser avant d'adopter MCP**

1. **Ai-je vraiment besoin d'un agent ?** Ou est-ce qu'une API classique suffit ?  
2. **Le co√ªt est-il justifi√© ?** Le ROI est-il clair et mesurable ?  
3. **Mes tools sont-ils bien con√ßus ?** Descriptions pr√©cises, intentions claires, pas de redondance ?  
4. **Ai-je une gouvernance en place ?** Quotas, audit, s√©curit√© ?  
5. **Mon architecture est-elle pr√™te ?** MCP termine sur du d√©terministe, pas sur d'autres agents ?

#### **Quand MCP brille vraiment**

MCP devient pertinent quand vous devez :

* Orchestrer des d√©cisions complexes entre plusieurs syst√®mes  
* Donner √† un utilisateur une interface conversationnelle qui a du sens  
* Automatiser du raisonnement m√©tier √† forte valeur ajout√©e  
* Permettre √† l'IA d'explorer des possibilit√©s que vous n'aviez pas anticip√©es

#### **L'avenir de MCP**

MCP est encore jeune. Les patterns √©mergent, les erreurs se r√©p√®tent, les architectures se stabilisent. Ce qui est certain, c'est que **l'IA conversationnelle ne dispara√Ætra pas**, et qu'elle devra dialoguer avec nos SI existants.

MCP n'est probablement pas la solution finale, mais c'est **la premi√®re tentative s√©rieuse de standardisation** de cette interface entre l'intelligence artificielle et les syst√®mes d'information.

#### **Le mot de la fin**

MCP ne remplace ni un moteur de recherche, ni une base de donn√©es, ni un backend d'API.

Utilisez-le avec discernement. Gouvernez-le avec rigueur. Et surtout, ne l'utilisez que quand il apporte vraiment quelque chose que vous ne pourriez pas faire autrement.

Parce qu'au final, la vraie question n'est pas "Puis-je utiliser MCP ?" mais "Dois-je vraiment utiliser MCP ?"
